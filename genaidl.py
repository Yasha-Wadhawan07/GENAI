# -*- coding: utf-8 -*-
"""GENAIDL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y4vsURFzNaYXjtxuAFM0gb2zSJD6wBuz
"""

# Question 7  Build and train a simple auto-encoder for dimensionality reduction or data denoising on a dataset like MNIST

# -*- coding: utf-8 -*-
"""
A simple Dense Autoencoder implemented using TensorFlow/Keras
for dimensionality reduction and image reconstruction on MNIST.
"""

# IMPORTANT: If you receive a 'ModuleNotFoundError', run this command
# in a separate Jupyter cell before running the rest of the code:
# !pip install tensorflow numpy matplotlib

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Reshape

# --- 1. Load and Preprocess Data ---

# Import the specific dataset module here to ensure it's available when this cell runs
from tensorflow.keras.datasets import mnist

# Load the MNIST dataset
print("Loading MNIST dataset...")
(x_train, _), (x_test, _) = mnist.load_data()

# Normalize pixel values to be between 0 and 1
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Calculate the size of the input images
input_size = x_train.shape[1] * x_train.shape[2] # 28 * 28 = 784

# Flatten the images (28x28 to 784-dimensional vector)
x_train_flat = x_train.reshape((len(x_train), input_size))
x_test_flat = x_test.reshape((len(x_test), input_size))

print(f"Original input shape: {x_train.shape}")
print(f"Flattened input shape: {x_train_flat.shape}")


# --- 2. Define Autoencoder Architecture ---

# Define the size of the latent space (dimensionality reduction)
encoding_dim = 32  # 784 dimensions reduced to 32

# ENCODER: Compresses the input data
encoder = Sequential([
    # Input layer takes 784 features
    Input(shape=(input_size,)),
    # First hidden layer
    Dense(128, activation='relu'),
    # The latent space layer (bottleneck)
    Dense(encoding_dim, activation='relu', name='latent_space')
], name='Encoder')

# DECODER: Reconstructs the input data from the latent space
decoder = Sequential([
    # Takes 32-dimensional latent vector as input
    Input(shape=(encoding_dim,)),
    # First reconstruction layer
    Dense(128, activation='relu'),
    # Output layer must match the original input size (784)
    # Use 'sigmoid' to keep output values between 0 and 1 (like input)
    Dense(input_size, activation='sigmoid')
], name='Decoder')

# AUTOENCODER: Links the encoder and decoder
autoencoder = Sequential([
    encoder,
    decoder
], name='Autoencoder')


# --- 3. Compile and Train the Model ---

# Compile the autoencoder
# 'binary_crossentropy' is common for normalized pixel data, or 'mse'
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

print("\n--- Autoencoder Summary ---")
autoencoder.summary()

# Train the model
print("\nTraining the Autoencoder (5 epochs)...")
history = autoencoder.fit(
    x_train_flat, x_train_flat, # Note: input (x) and target (y) are the same (unsupervised)
    epochs=5,                  # Keeping epochs low for quick execution
    batch_size=256,
    shuffle=True,              # Shuffle the data each epoch
    validation_data=(x_test_flat, x_test_flat) # Validate on the test set
)

print("\nTraining finished.")

# --- 4. Evaluate and Visualize Results ---

# Use the trained autoencoder to reconstruct the test images
reconstructed_images_flat = autoencoder.predict(x_test_flat)

# Reshape the reconstructed vectors back to 28x28 images for plotting
reconstructed_images = reconstructed_images_flat.reshape(x_test.shape)

# Plotting function
n = 10 # Number of digits to display
plt.figure(figsize=(20, 4))
plt.suptitle(f"Original vs. Reconstructed Images (Latent Dimension: {encoding_dim})", fontsize=16)

for i in range(n):
    # Display Original Images
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i])
    plt.title("Original")
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Display Reconstructed Images
    ax = plt.subplot(2, n, i + 1 + n)
    # Clip the values to ensure they are between 0 and 1 for proper display
    plt.imshow(np.clip(reconstructed_images[i], 0., 1.))
    plt.title("Reconstructed")
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()

# Optional: Plot the training loss
plt.figure(figsize=(8, 4))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.ylabel('Loss (Binary Crossentropy)')
plt.xlabel('Epoch')
plt.legend()
plt.show()





# question 8 Implement and compare LSTM and GRU networks for a sequence prediction task, like time-series forecasting.


# -*- coding: utf-8 -*-
"""
Implementation and comparison of LSTM and GRU networks for a time-series
forecasting task using a synthetic sine wave dataset.
"""

# --- 1. Imports ---
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense
from tensorflow.keras.callbacks import EarlyStopping

# --- 2. Synthetic Data Generation ---

# Generate a synthetic sine wave time series data
TIME_STEPS = 500
np.random.seed(42)
time = np.arange(0, TIME_STEPS, 1)
# Sine wave with some random noise
data = np.sin(time / 20) + np.random.normal(0, 0.1, TIME_STEPS)
data = data.reshape(-1, 1) # Reshape for scaling (N samples, 1 feature)

# --- 3. Preprocessing (Scaling and Sequence Creation) ---

# Import the necessary scaler here to ensure it's available when this section runs
from sklearn.preprocessing import MinMaxScaler

# Scale the data to be between 0 and 1 (important for RNNs)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Function to create sequences (X: look_back sequence, Y: next value)
def create_sequences(dataset, look_back=10):
    X, Y = [], []
    for i in range(len(dataset) - look_back):
        # Current sequence (X)
        seq = dataset[i:(i + look_back), 0]
        X.append(seq)
        # Next value to predict (Y)
        Y.append(dataset[i + look_back, 0])
    # Convert lists to NumPy arrays
    return np.array(X), np.array(Y)

# Define the look-back window (sequence length)
LOOK_BACK = 15

# Create the sequences
X, Y = create_sequences(scaled_data, LOOK_BACK)

# Reshape input to be (samples, time_steps, features) - required by Keras RNN layers
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split into training and testing sets (80/20 split)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = Y[:train_size], Y[train_size:]

print(f"Training data shape: X={X_train.shape}, Y={Y_train.shape}")
print(f"Test data shape: X={X_test.shape}, Y={Y_test.shape}")


# --- 4. Model Definition: LSTM Network ---
def build_lstm_model(look_back):
    model = Sequential([
        # LSTM layer: 50 units, returns sequences for Deep RNN (optional, here we only use 1 layer)
        # Input shape must match (time_steps, features)
        LSTM(50, input_shape=(look_back, 1)),
        # Dense layer for output (predicting 1 single value)
        Dense(1)
    ], name='LSTM_Model')
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# --- 5. Model Definition: GRU Network ---
def build_gru_model(look_back):
    model = Sequential([
        # GRU layer: 50 units, generally faster and simpler than LSTM
        GRU(50, input_shape=(look_back, 1)),
        # Dense layer for output (predicting 1 single value)
        Dense(1)
    ], name='GRU_Model')
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# --- 6. Train and Predict ---

# Initialize models
lstm_model = build_lstm_model(LOOK_BACK)
gru_model = build_gru_model(LOOK_BACK)

# Define early stopping to prevent overfitting and speed up training
es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

print("\n--- Training LSTM Model ---")
# Train the LSTM model
lstm_history = lstm_model.fit(
    X_train, Y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_test, Y_test),
    callbacks=[es],
    verbose=0 # Set to 1 to see epoch progress
)

print("--- Training GRU Model ---")
# Train the GRU model
gru_history = gru_model.fit(
    X_train, Y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_test, Y_test),
    callbacks=[es],
    verbose=0 # Set to 1 to see epoch progress
)

# Make predictions
lstm_predict_scaled = lstm_model.predict(X_test)
gru_predict_scaled = gru_model.predict(X_test)

# Inverse transform predictions to get actual values
lstm_predict = scaler.inverse_transform(lstm_predict_scaled)
gru_predict = scaler.inverse_transform(gru_predict_scaled)
Y_test_actual = scaler.inverse_transform(Y_test.reshape(-1, 1))

# --- 7. Comparison and Visualization ---

# Calculate performance (Root Mean Squared Error)
from sklearn.metrics import mean_squared_error
lstm_rmse = np.sqrt(mean_squared_error(Y_test_actual, lstm_predict))
gru_rmse = np.sqrt(mean_squared_error(Y_test_actual, gru_predict))

print(f"\n--- Model Performance Comparison (RMSE) ---")
print(f"LSTM Test RMSE: {lstm_rmse:.4f}")
print(f"GRU Test RMSE: {gru_rmse:.4f}")

# Plot the comparison
plt.figure(figsize=(15, 6))

# Plot the actual data
plt.plot(scaler.inverse_transform(scaled_data)[LOOK_BACK:], label='Original Data', color='gray', alpha=0.6)

# Plot the predictions over the test set range
test_start_index = train_size + LOOK_BACK
test_indices = np.arange(test_start_index, test_start_index + len(Y_test))

plt.plot(test_indices, Y_test_actual, label='Actual Test Values', color='black', linewidth=2)
plt.plot(test_indices, lstm_predict, label='LSTM Predictions', color='blue', linestyle='--')
plt.plot(test_indices, gru_predict, label='GRU Predictions', color='red', linestyle=':')

plt.title('LSTM vs GRU Forecasting Comparison')
plt.xlabel('Time Step')
plt.ylabel('Value')
plt.axvline(x=test_start_index, color='green', linestyle='-', linewidth=1, label='Train/Test Split')
plt.legend()
plt.grid(True)
plt.show()


##### question 9 # question 8 Implement and compare LSTM and GRU networks for a sequence prediction task, like time-series forecasting.

# -*- coding: utf-8 -*-
"""
A simple Recurrent Neural Network (RNN) implementation using Keras's SimpleRNN
layer to predict the next value in a synthetic time series sequence.
"""

# --- 1. Imports ---
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense

# --- 2. Synthetic Data Generation ---

# Generate a sequence based on a simple function (e.g., sine wave with noise)
TIME_STEPS = 400
np.random.seed(42)
# FIX: Corrected typo from TIME_STEES to TIME_STEPS
time = np.arange(0, TIME_STEPS, 1)
# Create sequential data with a pattern and some noise
raw_data = np.sin(time * 0.1) + (time / 100.0) + np.random.normal(0, 0.1, TIME_STEPS)
raw_data = raw_data.reshape(-1, 1) # Reshape to (N samples, 1 feature)

# --- 3. Preprocessing (Scaling and Sequence Creation) ---

# Import the necessary scaler
from sklearn.preprocessing import MinMaxScaler

# Scale the data to be between 0 and 1 (essential for RNN stability)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(raw_data)

# Function to create sequences (X: input sequence, Y: value to predict)
def create_sequences(dataset, look_back=10):
    X, Y = [], []
    for i in range(len(dataset) - look_back):
        # X: The sequence of 'look_back' previous values
        seq = dataset[i:(i + look_back), 0]
        X.append(seq)
        # Y: The next value in the sequence
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

# Define the look-back window (sequence length the RNN sees)
LOOK_BACK = 10

# Create the sequences
X, Y = create_sequences(scaled_data, LOOK_BACK)

# Reshape input to be (samples, time_steps, features) - Keras RNN requirement
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split into training and testing sets (e.g., 80% train, 20% test)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = Y[:train_size], Y[train_size:]

print(f"RNN Input Sequence Length (Look Back): {LOOK_BACK}")
print(f"Training data shape: X={X_train.shape}, Y={Y_train.shape}")


# --- 4. Define and Train SimpleRNN Model ---

# Define the SimpleRNN model architecture
model = Sequential([
    # SimpleRNN layer: The core recurrent layer.
    # units=32 defines the dimensionality of the hidden state (memory)
    SimpleRNN(units=32, input_shape=(LOOK_BACK, 1), activation='relu'),
    # Output dense layer: Predicts a single continuous value
    Dense(1)
], name='Simple_RNN_Model')

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

print("\n--- Model Summary ---")
model.summary()

# Train the model
print("\nTraining the Simple RNN...")
history = model.fit(
    X_train, Y_train,
    epochs=10,                # Keep epochs low for simplicity/speed
    batch_size=16,
    validation_data=(X_test, Y_test),
    verbose=0
)

print("\nTraining finished.")


# --- 5. Evaluate and Visualize Results ---

# Make predictions on the test set
predicted_scaled = model.predict(X_test)

# Inverse transform predictions to original scale for visualization
predicted_actual = scaler.inverse_transform(predicted_scaled)
Y_test_actual = scaler.inverse_transform(Y_test.reshape(-1, 1))

# Create indices for the test set predictions on the original timeline
test_indices = np.arange(train_size + LOOK_BACK, len(raw_data))

# Plot the comparison
plt.figure(figsize=(15, 6))

# Plot the full original data
plt.plot(raw_data, label='Full Original Data', color='gray', alpha=0.6)

# Plot the predictions over the test set range
plt.plot(test_indices, predicted_actual, label='RNN Predictions', color='blue', linewidth=2)
plt.plot(test_indices, Y_test_actual, label='Actual Test Values', color='red', linestyle=':')

plt.title('Simple RNN Prediction of Sequential Data')
plt.xlabel('Time Step')
plt.ylabel('Value')
# Highlight the split point between training and testing data
plt.axvline(x=train_size + LOOK_BACK, color='green', linestyle='--', linewidth=1, label='Train/Test Split Start')
plt.legend()
plt.grid(True)
plt.show()




### question 10 10.	Implement a basic Generative Adversarial Network (GAN) to generate new, synthetic images (e.g., handwritten digits).	35

# -*- coding: utf-8 -*-
"""
A simple Generative Adversarial Network (GAN) to generate synthetic
handwritten digits (MNIST-like images).

This code implements a basic GAN with fully connected layers for both
the Generator and Discriminator, using the MNIST dataset.
"""

# --- 1. Imports ---
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Dense, LeakyReLU, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import initializers # For weight initialization

# --- 2. Configuration Parameters ---
IMG_ROWS, IMG_COLS = 28, 28
# FIX: Corrected typo from COLS to IMG_COLS
IMG_DIM = IMG_ROWS * IMG_COLS # 784 for MNIST images
LATENT_DIM = 100              # Dimension of the random noise vector
EPOCHS = 30                   # Number of training epochs (can increase for better results)
BATCH_SIZE = 64
SAVE_INTERVAL = 5             # Interval to display generated images

# --- 3. Data Loading and Preprocessing ---

# Load the MNIST dataset
print("Loading and preprocessing MNIST data...")
(X_train, _), (_, _) = mnist.load_data()

# Reshape images to a 1D vector (784 features) and normalize to [-1, 1]
# GANs often perform better with data centered around zero.
X_train = X_train.reshape(-1, IMG_DIM).astype("float32") / 127.5 - 1
print(f"Processed training data shape: {X_train.shape}")

# --- 4. Generator Model ---
def build_generator():
    model = Sequential(name='Generator')

    # Input layer takes the random noise (latent_dim)
    # Use GlorotNormal for weight initialization
    model.add(Dense(256, input_dim=LATENT_DIM,
                    kernel_initializer=initializers.GlorotNormal()))
    model.add(LeakyReLU(alpha=0.2)) # LeakyReLU helps prevent vanishing gradients

    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))

    model.add(Dense(1024))
    model.add(LeakyReLU(alpha=0.2))

    # Output layer: Generate an image with IMG_DIM pixels, tanh activation for [-1, 1] range
    model.add(Dense(IMG_DIM, activation='tanh'))
    return model

# --- 5. Discriminator Model ---
def build_discriminator():
    model = Sequential(name='Discriminator')

    # Input layer takes a flattened image (IMG_DIM)
    model.add(Dense(1024, input_dim=IMG_DIM,
                    kernel_initializer=initializers.GlorotNormal()))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3)) # Dropout for regularization

    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))

    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))

    # Output layer: Binary classification (real/fake image), sigmoid for [0, 1] probability
    model.add(Dense(1, activation='sigmoid'))

    # Compile the model with binary cross-entropy loss and Adam optimizer
    optimizer = Adam(learning_rate=0.0002, beta_1=0.5)
    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

# --- 6. Combined GAN Model ---
def build_gan(generator, discriminator):
    # For the combined GAN model, the discriminator's weights are not trainable
    # during the generator's training step.
    discriminator.trainable = False

    # The GAN takes noise as input and outputs a classification from the discriminator
    noise_input = generator.input
    generated_image = generator(noise_input)
    gan_output = discriminator(generated_image)

    # This model stacks the generator and discriminator
    gan = Sequential([generator, discriminator], name='GAN')

    # Compile the GAN (used to train the generator)
    optimizer = Adam(learning_rate=0.0002, beta_1=0.5)
    # The generator wants the discriminator to output 1 (real) for its fake images
    gan.compile(loss='binary_crossentropy', optimizer=optimizer)
    return gan

# --- 7. Plotting Function ---
def plot_generated_images(generator, epoch, examples=10, dim=(1, 10), figsize=(10, 1)):
    # Generate random noise for input
    noise = np.random.normal(0, 1, size=[examples, LATENT_DIM])
    # Predict (generate) images
    generated_images = generator.predict(noise, verbose=0)

    # Rescale images from [-1, 1] to [0, 1] for plotting
    generated_images = (generated_images + 1) / 2.0
    # Reshape to 28x28 for display
    generated_images = generated_images.reshape(examples, IMG_ROWS, IMG_COLS)

    plt.figure(figsize=figsize)
    for i in range(generated_images.shape[0]):
        plt.subplot(dim[0], dim[1], i + 1)
        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')
        plt.axis('off')
    plt.suptitle(f"Epoch {epoch} - Generated Images", fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.9])
    plt.show()

# --- 8. Training Loop ---
def train_gan_model(generator, discriminator, gan):
    # Labels for real (1) and fake (0) images
    # Use label smoothing for real images (e.g., 0.9) to stabilize training
    real_labels = np.ones((BATCH_SIZE, 1)) * 0.9
    fake_labels = np.zeros((BATCH_SIZE, 1))

    # Number of batches per epoch
    batches_per_epoch = int(X_train.shape[0] / BATCH_SIZE)

    for epoch in range(1, EPOCHS + 1):
        print(f"\n--- Epoch {epoch}/{EPOCHS} ---")

        for batch_num in range(batches_per_epoch):

            # --- Train Discriminator ---

            # Get a random batch of real images
            idx = np.random.randint(0, X_train.shape[0], BATCH_SIZE)
            real_images = X_train[idx]

            # Generate a batch of fake images from random noise
            noise = np.random.normal(0, 1, size=[BATCH_SIZE, LATENT_DIM])
            fake_images = generator.predict(noise, verbose=0)

            # Train the discriminator on both real and fake images
            d_loss_real = discriminator.train_on_batch(real_images, real_labels)
            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) # Average loss

            # --- Train Generator ---

            # Generate new noise for the generator to create images
            noise = np.random.normal(0, 1, size=[BATCH_SIZE, LATENT_DIM])
            # Train the GAN (Generator) to make the discriminator classify its output as real (label 1)
            g_loss = gan.train_on_batch(noise, real_labels)

            # --- Reporting ---
            if batch_num % 100 == 0:
                print(f"  Batch {batch_num}/{batches_per_epoch} | D Loss: {d_loss[0]:.4f} (Acc: {d_loss[1]*100:.2f}%) | G Loss: {g_loss:.4f}")

        # Display generated images periodically
        if epoch % SAVE_INTERVAL == 0:
            plot_generated_images(generator, epoch)

# --- 9. Main Execution ---
if __name__ == '__main__':
    # Build the Discriminator, Generator, and combined GAN models
    discriminator = build_discriminator()
    generator = build_generator()
    gan = build_gan(generator, discriminator)

    # Print model summaries
    print("\n--- Generator Summary ---")
    generator.summary()
    print("\n--- Discriminator Summary ---")
    discriminator.summary()
    print("\n--- Combined GAN Summary (for Generator training) ---")
    gan.summary()

    print("\n--- Starting GAN Training ---")
    train_gan_model(generator, discriminator, gan)
    print("\n--- Training Complete ---")

    # Plot final generated samples
    plot_generated_images(generator, EPOCHS, examples=20, dim=(2, 10), figsize=(12, 2.5))




    ###### Question 11  Use a pre-trained model like Stable Diffusion to generate images based on various textual descriptions (text-to-image).

    # -*- coding: utf-8 -*-
"""
Implements text-to-image generation using the Imagen 3.0 model
(gemini-2.5-flash-image-preview API structure), based on a textual prompt.
"""

# --- 1. Imports ---
import requests
import json
import base64
import io
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# --- 2. Configuration (MANDATORY for Canvas Environment) ---
# NOTE: The API key is automatically provided at runtime in the Canvas environment.
API_KEY = ""
API_URL = "https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=" + API_KEY

# --- 3. Image Generation Function ---
def generate_image_from_text(prompt: str):
    """
    Calls the Imagen 3.0 API to generate an image from a text prompt.
    """
    print(f"Generating image for prompt: '{prompt}'...")

    # Define the request payload for the Imagen 3.0 model
    payload = {
        "instances": {
            "prompt": prompt,
            "config": {
                "number_of_images": 1,
                "aspect_ratio": "1:1"
            }
        },
        "parameters": {
            "sampleCount": 1
        }
    }

    try:
        # Make the API request (synchronous request)
        response = requests.post(
            API_URL,
            headers={'Content-Type': 'application/json'},
            data=json.dumps(payload)
        )
        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)

        # Parse the JSON response
        result = response.json()

        # Extract the base64 encoded image data
        if result.get('predictions') and result['predictions'][0].get('bytesBase64Encoded'):
            base64_data = result['predictions'][0]['bytesBase64Encoded']
        else:
            print("Error: Could not find image data in API response.")
            print(json.dumps(result, indent=2))
            return

        # Decode the base64 string to binary image data
        image_data = base64.b64decode(base64_data)

        # Open the image using PIL (Pillow)
        image = Image.open(io.BytesIO(image_data))

        # --- Display the image using Matplotlib ---
        plt.figure(figsize=(8, 8))
        plt.imshow(np.array(image))
        plt.title("Generated Image from Text Prompt")
        plt.axis('off') # Hide axes for better visual
        plt.show()

    except requests.exceptions.RequestException as e:
        print(f"API Request Error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

# --- 4. Execution Example ---

# Define the text prompt for image generation
# You can easily change this prompt to compare different results
# Try "A futuristic city skyline during a neon sunset, digital art"
TEXT_PROMPT = "A cute, fluffy corgi wearing a tiny wizard hat, sitting on a log in a misty forest, highly detailed digital painting."

# Run the generation function
generate_image_from_text(TEXT_PROMPT)




############ Question 12 Implement a deep learning model (e.g., a CNN or GAN) to automatically add realistic color to grayscale images.

# -*- coding: utf-8 -*-
"""
Implementation of a simple CNN Encoder-Decoder model for image colorization.
This script uses a subset of the CIFAR-10 dataset for fast execution.
"""

# --- 1. Imports ---
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.layers import Conv2D, UpSampling2D, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from skimage.color import rgb2lab, lab2rgb # Required for L*a*b color space conversion

# --- 2. Configuration Parameters ---
IMG_SIZE = 32           # CIFAR-10 image size
BATCH_SIZE = 32
EPOCHS = 10             # Keep epochs low for quick execution
NUM_SAMPLES = 1000      # Use a small subset of the dataset for speed

# --- 3. Data Loading and Preprocessing ---

print("Loading CIFAR-10 data...")
(X_train, _), (_, _) = cifar10.load_data()

# Use only a small subset for demonstration and speed
X_train = X_train[:NUM_SAMPLES]

def preprocess_data(rgb_images):
    """Converts RGB images to L*a*b color space and splits them."""

    # Normalize RGB to [0, 1]
    rgb_images = rgb_images.astype('float32') / 255.0

    # Convert RGB to Lab
    lab_images = np.array([rgb2lab(img) for img in rgb_images])

    # L channel (Grayscale/Luminosity) is the input
    L_channel = lab_images[:, :, :, 0]
    # Scale L channel to [0, 1] range for network input
    L_channel = L_channel / 100.0
    L_channel = np.expand_dims(L_channel, axis=-1)

    # a and b channels (Color components) are the output target
    ab_channels = lab_images[:, :, :, 1:]
    # Scale a and b channels to [-1, 1] range
    ab_channels = ab_channels / 128.0

    return L_channel, ab_channels, rgb_images

# Prepare data
X_L, Y_ab, X_rgb = preprocess_data(X_train)
print(f"Input L channel shape (Grayscale): {X_L.shape}")
print(f"Target ab channels shape (Color): {Y_ab.shape}")

# --- 4. Colorizer CNN Model (Encoder-Decoder) ---
def build_colorizer(input_shape):
    """
    Builds a simple U-Net-like Encoder-Decoder model for colorization.
    Encoder (Downsampling) and Decoder (Upsampling) layers are used.
    """
    input_img = Input(shape=input_shape)

    # Encoder (Downsampling)
    x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(input_img)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(x)

    # Decoder (Upsampling)
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    # Upsample back to the original size (32x32)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)

    # Output layer: 2 channels (a and b) with tanh activation to match [-1, 1] range
    output_ab = Conv2D(2, (3, 3), activation='tanh', padding='same')(x)

    model = Model(inputs=input_img, outputs=output_ab)

    # Compile the model with Adam optimizer and mean squared error loss
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
    return model

# --- 5. Training and Execution ---

# Build the model
colorizer = build_colorizer(input_shape=(IMG_SIZE, IMG_SIZE, 1))
print("\n--- Colorizer Model Summary ---")
colorizer.summary()

# Train the model
print("\n--- Starting Model Training ---")
colorizer.fit(X_L, Y_ab,
              batch_size=BATCH_SIZE,
              epochs=EPOCHS,
              verbose=1)
print("\n--- Training Complete ---")

# --- 6. Prediction and Visualization ---
def visualize_results(L_channel_input, ab_channel_predicted, original_rgb):
    """
    Combines the input L channel with the predicted a and b channels
    and displays the results compared to the original image.
    """

    # Denormalize predicted a and b channels: [-1, 1] -> [-128, 128]
    ab_channel_predicted = ab_channel_predicted * 128.0

    # Denormalize input L channel: [0, 1] -> [0, 100]
    L_channel_input = L_channel_input * 100.0

    # Combine L and ab channels
    # We take the first predicted sample
    combined_lab = np.zeros((IMG_SIZE, IMG_SIZE, 3))
    combined_lab[:, :, 0] = L_channel_input[0, :, :, 0] # L channel (Grayscale input)
    combined_lab[:, :, 1:] = ab_channel_predicted[0]    # Predicted ab channels

    # Convert Lab back to RGB
    predicted_rgb = lab2rgb(combined_lab)

    # Create grayscale version for comparison (Input)
    grayscale_img = L_channel_input[0, :, :, 0]

    # Plotting
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.imshow(grayscale_img, cmap='gray')
    plt.title('1. Grayscale Input (L)')
    plt.axis('off')

    plt.subplot(1, 3, 2)
    # The original image is already normalized to [0, 1]
    plt.imshow(original_rgb[0])
    plt.title('2. Original Color (Target)')
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(predicted_rgb)
    plt.title('3. Predicted Color')
    plt.axis('off')

    plt.show()

# Get predictions for the first sample
predicted_ab = colorizer.predict(X_L[:1], verbose=0)

# Visualize the comparison (Input, Target, Predicted)
visualize_results(X_L, predicted_ab, X_rgb)





####################Question 11 Use a pre-trained model like Stable Diffusion to generate images based on various textual descriptions (text-to-image).

# -*- coding: utf-8 -*-
"""
Implements text-to-image generation using the Imagen 3.0 model
(gemini-2.5-flash-image-preview API structure), based on a textual prompt.
"""

# --- 1. Imports ---
import requests
import json
import base64
import io
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# --- 2. Configuration (MANDATORY for Canvas Environment) ---
# NOTE: The API key is automatically provided at runtime in the Canvas environment.
API_KEY = ""
API_URL = "https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=" + API_KEY

# --- 3. Image Generation Function ---
def generate_image_from_text(prompt: str):
    """
    Calls the Imagen 3.0 API to generate an image from a text prompt.
    """
    print(f"Generating image for prompt: '{prompt}'...")

    # Define the request payload for the Imagen 3.0 model
    payload = {
        "instances": {
            "prompt": prompt,
            "config": {
                "number_of_images": 1,
                "aspect_ratio": "1:1"
            }
        },
        "parameters": {
            "sampleCount": 1
        }
    }

    try:
        # Make the API request (synchronous request)
        response = requests.post(
            API_URL,
            headers={'Content-Type': 'application/json'},
            data=json.dumps(payload)
        )
        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)

        # Parse the JSON response
        result = response.json()

        # Extract the base64 encoded image data
        if result.get('predictions') and result['predictions'][0].get('bytesBase64Encoded'):
            base64_data = result['predictions'][0]['bytesBase64Encoded']
        else:
            print("Error: Could not find image data in API response.")
            print(json.dumps(result, indent=2))
            return

        # Decode the base64 string to binary image data
        image_data = base64.b64decode(base64_data)

        # Open the image using PIL (Pillow)
        image = Image.open(io.BytesIO(image_data))

        # --- Display the image using Matplotlib ---
        plt.figure(figsize=(8, 8))
        plt.imshow(np.array(image))
        plt.title("Generated Image from Text Prompt")
        plt.axis('off') # Hide axes for better visual
        plt.show()

    except requests.exceptions.RequestException as e:
        print(f"API Request Error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

# --- 4. Execution Example ---

# Define the text prompt for image generation
# You can easily change this prompt to compare different results
# Try "A futuristic city skyline during a neon sunset, digital art"
TEXT_PROMPT = "A cute, fluffy corgi wearing a tiny wizard hat, sitting on a log in a misty forest, highly detailed digital painting."

# Run the generation function
generate_image_from_text(TEXT_PROMPT)




############QUESTION 13 13.	Train a generative model, such as a GAN or RNN or suitable pretrained models, to compose and generate new musical sequences in MIDI/wav format.	40

# -*- coding: utf-8 -*-
"""
Implements a simple RNN (LSTM) to learn and generate a short musical sequence.
This demonstrates the core sequential generation principle.
"""

# --- 1. Imports ---
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical

# --- 2. Configuration and Data ---

# Define a simple vocabulary of notes for the model to learn
NOTES = ['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5', 'rest']
VOCAB_SIZE = len(NOTES)
NOTE_TO_INT = {note: i for i, note in enumerate(NOTES)}
INT_TO_NOTE = {i: note for i, note in enumerate(NOTES)}

# Example input sequence (a very simple tune)
# In a real application, this would be a large MIDI dataset.
raw_sequence = ['C4', 'E4', 'G4', 'C5', 'rest', 'G4', 'E4', 'C4', 'D4', 'F4', 'A4', 'G4']
SEQUENCE_LENGTH = 3 # How many past notes to use to predict the next

# --- 3. Data Preprocessing for RNN ---

X = [] # Input sequences (e.g., [C4, E4, G4])
y = [] # Target notes (e.g., C5)

# Create overlapping sequences
for i in range(0, len(raw_sequence) - SEQUENCE_LENGTH, 1):
    input_seq = raw_sequence[i:i + SEQUENCE_LENGTH]
    output_note = raw_sequence[i + SEQUENCE_LENGTH]

    # Convert notes to integers
    input_ints = [NOTE_TO_INT[note] for note in input_seq]
    output_int = NOTE_TO_INT[output_note]

    X.append(input_ints)
    y.append(output_int)

NUM_SEQUENCES = len(X)

# Reshape X to fit RNN input: (samples, sequence_length, features)
# The "features" dimension is 1 since we are using integer encoding
X = np.reshape(X, (NUM_SEQUENCES, SEQUENCE_LENGTH, 1))

# Normalize input integers (simple division for numerical stability)
X = X / float(VOCAB_SIZE)

# One-hot encode the output targets
y = to_categorical(y, num_classes=VOCAB_SIZE)

print(f"Total training sequences: {NUM_SEQUENCES}")
print(f"RNN input shape: {X.shape}")

# --- 4. Define LSTM Model ---
def build_music_rnn():
    """Builds a simple one-layer LSTM model."""
    model = Sequential(name='Music_LSTM')

    # LSTM layer: processes sequential input
    model.add(LSTM(
        256,
        input_shape=(X.shape[1], X.shape[2]),
        return_sequences=False # We only need the output from the last step
    ))

    # Dense layer to map LSTM output to note space
    model.add(Dense(VOCAB_SIZE))

    # Softmax activation to get probability distribution over the notes
    model.add(Activation('softmax'))

    model.compile(loss='categorical_crossentropy', optimizer='adam')
    return model

# --- 5. Training ---
music_rnn = build_music_rnn()
music_rnn.summary()

print("\n--- Starting Music RNN Training ---")
# Train the model (low epochs since data set is tiny, increase for real data)
music_rnn.fit(X, y, epochs=50, batch_size=1, verbose=0)
print("\n--- Training Complete ---")

# --- 6. Generation ---
def generate_music_sequence(model, start_sequence, length=20):
    """Uses the trained model to generate a new sequence of notes."""

    # Start with a sequence from the original data (e.g., the first one)
    pattern = [NOTE_TO_INT[note] for note in start_sequence]
    generated_sequence = start_sequence

    for _ in range(length):
        # Reshape and normalize input pattern for prediction
        input_data = np.reshape(pattern, (1, len(pattern), 1))
        input_data = input_data / float(VOCAB_SIZE)

        # Predict the next note (returns probability vector)
        prediction = model.predict(input_data, verbose=0)

        # Select the note with the highest probability
        index = np.argmax(prediction)
        result = INT_TO_NOTE[index]

        # Add the predicted note to the output list
        generated_sequence.append(result)

        # Update the pattern: drop the oldest note and add the new one
        pattern.append(index)
        pattern = pattern[1:len(pattern)]

    return generated_sequence

# Choose a starting sequence from the beginning of the data
start_seq = raw_sequence[:SEQUENCE_LENGTH]
generated_notes = generate_music_sequence(music_rnn, start_seq, length=15)

# --- 7. Output ---
print("\n--- Original Short Sequence ---")
print(raw_sequence)
print("\n--- Generated Musical Sequence ---")
print(generated_notes)



###### Question 14 Use the Hugging Face Transformers library to fine-tune a pre-trained model for machine translation between two languages.

# -*- coding: utf-8 -*-
"""
Fine-tunes a pre-trained MarianMT model for machine translation (English to French)
using a small subset of the WMT dataset.
"""

# --- 1. Installation Note ---
# NOTE: This code assumes you have the following packages installed:
# !pip install transformers datasets accelerate evaluate sacrebleu

# --- 2. Imports ---
import numpy as np
from datasets import load_dataset, load_metric
from transformers import (
    AutoTokenizer,
    AutoModelForSeq2SeqLM,
    DataCollatorForSeq2Seq,
    Seq2SeqTrainingArguments,
    Seq2SeqTrainer,
)

# --- 3. Configuration and Setup ---

# Model trained specifically for English -> French translation
MODEL_CHECKPOINT = "Helsinki-NLP/opus-mt-en-fr"
SOURCE_LANG = "en"
TARGET_LANG = "fr"
MAX_LENGTH = 128
BATCH_SIZE = 16
LEARNING_RATE = 2e-5
NUM_TRAIN_EPOCHS = 3 # Keep low for quick execution

# --- 4. Load Data and Tokenizer ---

# Load a small sample dataset (SacreBLEU is the standard metric for MT)
raw_datasets = load_dataset("wmt16", "de-en", split='train[:1%]') # Using a tiny fraction of a large dataset
# For simplicity, we'll rename columns to match the translation pair
raw_datasets = raw_datasets.rename_column("translation", "translation_pair")
raw_datasets = raw_datasets.train_test_split(test_size=0.1)

# Load the tokenizer associated with the pre-trained model
tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)

# --- 5. Preprocessing Function ---
def preprocess_function(examples):
    """Tokenizes both the source and target sentences."""

    # Extract source (English) sentences and tokenize
    inputs = [ex[SOURCE_LANG] for ex in examples["translation_pair"]]
    model_inputs = tokenizer(inputs, max_length=MAX_LENGTH, truncation=True)

    # Extract target (French) sentences for the labels
    with tokenizer.as_target_tokenizer():
        labels = tokenizer([ex[TARGET_LANG] for ex in examples["translation_pair"]],
                           max_length=MAX_LENGTH,
                           truncation=True)

    # Assign tokenized labels (input_ids) to the model's labels key
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

# Apply the preprocessing function to the entire dataset
tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)

# --- 6. Load Model and Define Metric ---

# Load the sequence-to-sequence model
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)

# Load the SacreBLEU metric
metric = load_metric("sacrebleu")

def compute_metrics(eval_preds):
    """Computes SacreBLEU score during evaluation."""
    preds, labels = eval_preds
    if isinstance(preds, tuple):
        preds = preds[0]

    # Decode predictions and labels
    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)

    # Replace -100 in the labels as they are added by the Data Collator for padding
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Metric requires labels as list of references
    decoded_labels = [[label] for label in decoded_labels]

    # Compute the metric
    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    return {"bleu": result["score"]}

# --- 7. Define Training Arguments and Trainer ---

# Define arguments for the training process
training_args = Seq2SeqTrainingArguments(
    output_dir="./mt_finetuned",              # Output directory for checkpoints
    num_train_epochs=NUM_TRAIN_EPOCHS,        # Number of training epochs
    per_device_train_batch_size=BATCH_SIZE,   # Batch size per device
    per_device_eval_batch_size=BATCH_SIZE,    # Batch size for evaluation
    learning_rate=LEARNING_RATE,              # Standard fine-tuning learning rate
    weight_decay=0.01,                        # Regularization
    save_total_limit=1,                       # Only save the best model
    evaluation_strategy="epoch",              # Evaluate at the end of each epoch
    logging_dir='./logs',                     # Directory for Tensorboard logs
    fp16=False,                               # Set to True if using a supported GPU
)

# Data collator prepares batches of data, including padding
data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)

# Initialize the Trainer
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

# --- 8. Start Fine-Tuning ---
print("\n--- Starting Model Fine-Tuning (English -> French) ---")
trainer.train()
print("\n--- Fine-Tuning Complete ---")

# --- 9. Demonstration (Inference) ---
def translate(text):
    """Uses the fine-tuned model to translate a sentence."""
    # Tokenize the input text
    inputs = tokenizer(text, return_tensors="pt", max_length=MAX_LENGTH, truncation=True)

    # Generate the translation IDs
    translated_ids = model.generate(**inputs, max_new_tokens=MAX_LENGTH)

    # Decode the IDs back to text
    translation = tokenizer.decode(translated_ids[0], skip_special_tokens=True)
    return translation

# Example sentence to test the fine-tuned model
EXAMPLE_TEXT = "This is a simple sentence for machine translation."
translated_text = translate(EXAMPLE_TEXT)

print("\n--- Inference Example ---")
print(f"Source (EN): {EXAMPLE_TEXT}")
print(f"Target (FR): {translated_text}")